{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.functions import udf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.sql.types import NumericType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = \"/Library/Java/JavaVirtualMachines/jdk1.8.0_261.jdk/Contents/Home\"\n",
    "spark = SparkSession.builder.appName('Read CSV File into DataFrame'). getOrCreate()\n",
    "data = spark.read.csv(\"steam_reviews.csv\", header=True, inferSchema=True, multiLine=True, escape=\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, app_id: int, app_name: string, review_id: int, language: string, review: string, timestamp_created: int, timestamp_updated: bigint, recommended: boolean, votes_helpful: bigint, votes_funny: bigint, weighted_vote_score: double, comment_count: int, steam_purchase: boolean, received_for_free: boolean, written_during_early_access: boolean, author.steamid: bigint, author.num_games_owned: bigint, author.num_reviews: bigint, author.playtime_forever: double, author.playtime_last_two_weeks: double, author.playtime_at_review: double, author.last_played: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = data.where(data.language == 'english').select('review', 'recommended')\n",
    "negative = df.where(df.recommended == False)\n",
    "positive = df.where(df.recommended == True)\n",
    "num_negative = negative.count()\n",
    "positive = positive.limit(num_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|         review_pure|recommended|\n",
      "+--------------------+-----------+\n",
      "|They certainly du...|      false|\n",
      "|terribly bugs kee...|      false|\n",
      "|While there is a ...|      false|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = negative.union(positive)\n",
    "def text_process(data): \n",
    "    if not data:\n",
    "        return ''\n",
    "    tweet_blob = TextBlob(data)\n",
    "    words = tweet_blob.words\n",
    "    sent = ' '.join(words)\n",
    "    return sent \n",
    "processUDF = udf(lambda z: text_process(z))\n",
    "\n",
    "all_data = all_data.withColumn('review_pure', processUDF(all_data.review)).select('review_pure', 'recommended')\n",
    "all_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|       review_remove|recommended|\n",
      "+--------------------+-----------+\n",
      "|They certainly du...|      false|\n",
      "|terribly bugs kee...|      false|\n",
      "|While there is a ...|      false|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_junk(data): #function to keep only characters and remove 'user'- which is not required \n",
    "    words=[words for words in data.split() if words != 'user']    \n",
    "    clean_tokens = [t for t in words if re.match(r'[^\\W\\d]*$', t)] # Remove punctuations')]\n",
    "    sent_join  = ' '.join(clean_tokens)\n",
    "    return sent_join\n",
    "junkUDF = udf(lambda z: remove_junk(z))\n",
    "all_data = all_data.withColumn('review_remove', processUDF(all_data.review_pure)).select('review_remove', 'recommended')\n",
    "all_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          review_low|recommended|\n",
      "+--------------------+-----------+\n",
      "|they certainly du...|      false|\n",
      "|terribly bugs kee...|      false|\n",
      "|while lot content...|      false|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltkUDF = udf(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\n",
    "all_data = all_data.withColumn('review_low', nltkUDF(all_data.review_remove)).select('review_low', 'recommended')\n",
    "all_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              review|recommended|\n",
      "+--------------------+-----------+\n",
      "|they certainly du...|      false|\n",
      "|terribly bug keep...|      false|\n",
      "|while lot content...|      false|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "lemmaUDF = udf(lambda z: lemmatize_text(z))\n",
    "all_data = all_data.withColumn('review', lemmaUDF(all_data.review_low)).select('review', 'recommended')\n",
    "all_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+\n",
      "|              review|recommended|        review_array|\n",
      "+--------------------+-----------+--------------------+\n",
      "|they certainly du...|      false|[they, certainly,...|\n",
      "|terribly bug keep...|      false|[terribly, bug, k...|\n",
      "|while lot content...|      false|[while, lot, cont...|\n",
      "+--------------------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|            features|recommended|\n",
      "+--------------------+-----------+\n",
      "|(262144,[377,5381...|      false|\n",
      "|(262144,[17893,32...|      false|\n",
      "|(262144,[1232,230...|      false|\n",
      "+--------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(262144,[377,5381...|    0|\n",
      "|(262144,[17893,32...|    0|\n",
      "|(262144,[1232,230...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train, test = all_data.randomSplit(weights=[0.8, 0.2], seed=200)\n",
    "all_data = all_data.withColumn('review_array', split(all_data.review, ' '))\n",
    "all_data.show(3)\n",
    "ht = HashingTF(inputCol=\"review_array\", outputCol=\"features\")\n",
    "all_data = ht.transform(all_data).select('features', 'recommended')\n",
    "all_data.show(3)\n",
    "all_data = all_data.withColumn('label', all_data.recommended.cast('integer')).select('features', 'label')\n",
    "all_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|            features|recommended|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|(262144,[2,290,34...|      false|    0|[11.7671453688754...|[0.99999224484771...|       0.0|\n",
      "|(262144,[5,61544,...|      false|    0|[0.02540774383412...|[0.50635159427107...|       0.0|\n",
      "|(262144,[7,329,19...|      false|    0|[3.58689009589404...|[0.97306148163195...|       0.0|\n",
      "|(262144,[7,406,12...|      false|    0|[43.7660774271393...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,406,13...|      false|    0|[71.2469164705956...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,406,16...|      false|    0|[215.053746112153...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,471,12...|      false|    0|[70.4330012421775...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,1001,2...|      false|    0|[19.0251086724352...|[0.99999999453613...|       0.0|\n",
      "|(262144,[7,1141,2...|      false|    0|[54.3828071667099...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,1578,2...|      false|    0|[78.2185186258134...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,1578,2...|      false|    0|[36.1776152913017...|[0.99999999999999...|       0.0|\n",
      "|(262144,[7,2101,8...|      false|    0|[90.2751340986471...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,5139,1...|      false|    0|[62.823093395501,...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[7,19684,...|      false|    0|[45.3469518742134...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[9,113,60...|      false|    0|[31.5816382228575...|[0.99999999999998...|       0.0|\n",
      "|(262144,[9,161,40...|      false|    0|[79.9487068588369...|           [1.0,0.0]|       0.0|\n",
      "|(262144,[9,406,23...|      false|    0|[28.6835670250261...|[0.99999999999965...|       0.0|\n",
      "|(262144,[9,956,23...|      false|    0|[12.8149640650906...|[0.99999728023964...|       0.0|\n",
      "|(262144,[9,1578,3...|      false|    0|[5.61938146268439...|[0.99638622297102...|       0.0|\n",
      "|(262144,[9,1689,3...|      false|    0|[44.5651390282523...|           [1.0,0.0]|       0.0|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MulticlassClassificationEvaluator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4de61374aa00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# compute accuracy on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test set accuracy = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MulticlassClassificationEvaluator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train, test = all_data.randomSplit(weights=[0.8, 0.2], seed=200)\n",
    "\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = lrModel.transform(test) \n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.8774084263443236\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions) \n",
    "print(\"Test set accuracy = \" + str(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassificationEvaluator_60a413d95587"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the pickle file for Logistic model\n",
    "# lrModel.save(\"Model/lr_model\")\n",
    "# Creating a pickle file for the CountVectorizer\n",
    "ht.save(\"Model/hashing-tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|            features|recommended|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+----------+\n",
      "|(262144,[2,290,34...|      false|    0|[-15496.323883844...|[1.42041980037984...|       1.0|\n",
      "|(262144,[5,61544,...|      false|    0|[-82.185212929691...|[0.07787589300353...|       1.0|\n",
      "|(262144,[7,329,19...|      false|    0|[-275.61511147479...|[0.99963489985117...|       0.0|\n",
      "|(262144,[7,406,12...|      false|    0|[-2042.0309400764...|[1.0,9.1834702311...|       0.0|\n",
      "|(262144,[7,406,13...|      false|    0|[-6074.0115668025...|[1.0,6.6034342003...|       0.0|\n",
      "|(262144,[7,406,16...|      false|    0|[-6172.6692620398...|[1.0,4.5602046408...|       0.0|\n",
      "|(262144,[7,471,12...|      false|    0|[-2213.7309051816...|[1.0,4.8140139239...|       0.0|\n",
      "|(262144,[7,1001,2...|      false|    0|[-1347.9607118610...|[1.0,3.6211486783...|       0.0|\n",
      "|(262144,[7,1141,2...|      false|    0|[-1847.6815940832...|[1.0,5.5106222198...|       0.0|\n",
      "|(262144,[7,1578,2...|      false|    0|[-2188.2880229745...|[1.0,2.8416408991...|       0.0|\n",
      "|(262144,[7,1578,2...|      false|    0|[-2344.4681212737...|[1.0,2.7636740490...|       0.0|\n",
      "|(262144,[7,2101,8...|      false|    0|[-2951.4573917750...|[1.0,1.5168241449...|       0.0|\n",
      "|(262144,[7,5139,1...|      false|    0|[-1170.5770386288...|[1.0,4.8289888520...|       0.0|\n",
      "|(262144,[7,19684,...|      false|    0|[-857.35933571040...|[1.0,5.8587747462...|       0.0|\n",
      "|(262144,[9,113,60...|      false|    0|[-3572.1365652180...|[0.99999998108437...|       0.0|\n",
      "|(262144,[9,161,40...|      false|    0|[-5831.8083695407...|[1.0,2.5492982043...|       0.0|\n",
      "|(262144,[9,406,23...|      false|    0|[-2645.2834682957...|[1.0,3.1694078483...|       0.0|\n",
      "|(262144,[9,956,23...|      false|    0|[-1435.3973372771...|[0.99999998059760...|       0.0|\n",
      "|(262144,[9,1578,3...|      false|    0|[-1015.7945135790...|[0.99999995905653...|       0.0|\n",
      "|(262144,[9,1689,3...|      false|    0|[-1815.8375528504...|[1.0,3.8557847633...|       0.0|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(labelCol=\"label\", featuresCol=\"features\") \n",
    "nbModel = nb.fit(train)\n",
    "predictions = nbModel.transform(test) \n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbModel.save(\"Model/nb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.8893870064953269\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions) \n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
